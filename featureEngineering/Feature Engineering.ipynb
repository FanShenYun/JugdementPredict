{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件及檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('add_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['xword'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    for j in range(0,17):\n",
    "        df.iloc[i,j] = str(df.iloc[i,j]).replace(\"[\", '').replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\").replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i,15] = str(df.iloc[i,15]).replace(\"公然侮辱_1\", '309_1').replace(\"公然侮辱_2\",\"309_2\").replace(\"誹謗_1\",\"310_1\").replace(\"誹謗_2\",\"310_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['years', 'label']]=df[['years', 'label']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    for j in range(0,17):\n",
    "        if df.iloc[i,j] == 'nan':\n",
    "            df.iloc[i,j] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['simplejudge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['court'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['law'])['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['law'])['xword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['law'])['simplejudge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['law','simplejudge'])['label'].describe().applymap(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['law'])['label'].describe().applymap(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['label'],df['law']).T.style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='law', col_wrap=1, aspect=3)\n",
    "g.map(sns.histplot,'label',kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = df['law']=='309_1'\n",
    "pos = np.flatnonzero(mask)\n",
    "df309_1 = df.iloc[pos]\n",
    "# g = sns.FacetGrid(df309_1, col='simplejudge', col_wrap=1, aspect=3)\n",
    "# g.map(sns.histplot,'label',kde=False)\n",
    "sns.histplot(df309_1['label'],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = df['law']=='309_2'\n",
    "pos = np.flatnonzero(mask)\n",
    "df309_2 = df.iloc[pos]\n",
    "# g = sns.FacetGrid(df309_2, col='simplejudge', col_wrap=1, aspect=3)\n",
    "# g.map(sns.histplot,'label',kde=False)\n",
    "sns.histplot(df309_2['label'],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = df['law']=='310_1'\n",
    "pos = np.flatnonzero(mask)\n",
    "df310_1 = df.iloc[pos]\n",
    "# g = sns.FacetGrid(df310_1, col='simplejudge', col_wrap=1, aspect=3)\n",
    "# g.map(sns.histplot,'label',kde=False)\n",
    "sns.histplot(df310_1['label'],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = df['law']=='310_2'\n",
    "pos = np.flatnonzero(mask)\n",
    "df310_2 = df.iloc[pos]\n",
    "# g = sns.FacetGrid(df310_2, col='simplejudge', col_wrap=1, aspect=3)\n",
    "# g.map(sns.histplot,'label',kde=False)\n",
    "sns.histplot(df310_2['label'],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "sns.countplot(df['label'],hue=df['law'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 刪補空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['court'].isnull())\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['court'].fillna(value='市區', inplace=True)\n",
    "df['record'].fillna(value='無', inplace=True)\n",
    "df['place'].fillna(value='實體', inplace=True)\n",
    "df['compromise'].fillna(value='無', inplace=True)\n",
    "# df['xword'].fillna(value='無', inplace=True)\n",
    "df['education'].fillna(value='高中職', inplace=True)\n",
    "df['mind'].fillna(value='正常', inplace=True)\n",
    "df['financial'].fillna(value='正常', inplace=True)\n",
    "df['support'].fillna(value='無', inplace=True)\n",
    "df['attitude'].fillna(value='尚可', inplace=True)\n",
    "df['confess'].fillna(value='否', inplace=True)\n",
    "df['sequel'].fillna(value='否', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 離群值處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考慮最後應該會以分類模型作為學習，因此不採取log或平方方式\n",
    "print (\"Shape Of The Before Ouliers: \",df309_1.shape)\n",
    "n=1.5\n",
    "#IQR = Q3-Q1\n",
    "IQR = np.percentile(df309_1['label'],75) - np.percentile(df309_1['label'],25)\n",
    "#outlier = Q3 + n*IQR \n",
    "df309_1=df309_1[df309_1['label'] < np.percentile(df309_1['label'],75)+n*IQR]\n",
    "#outlier = Q1 - n*IQR \n",
    "df309_1=df309_1[df309_1['label'] > np.percentile(df309_1['label'],25)-n*IQR]\n",
    "print (\"Shape Of The After Ouliers: \",df309_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df309_1['label'],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df309_1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder() \n",
    "df2 = df.copy(deep=True)\n",
    "df2['simplejudge'] = labelencoder.fit_transform(df2['simplejudge']) \n",
    "df2['court'] = labelencoder.fit_transform(df2['court']) \n",
    "df2['record'] = labelencoder.fit_transform(df2['record']) \n",
    "df2['place'] = labelencoder.fit_transform(df2['place']) \n",
    "df2['compromise'] = labelencoder.fit_transform(df2['compromise']) \n",
    "df2['xword'] = labelencoder.fit_transform(df2['xword']) \n",
    "df2['education'] = labelencoder.fit_transform(df2['education']) \n",
    "df2['mind'] = labelencoder.fit_transform(df2['mind']) \n",
    "df2['financial'] = labelencoder.fit_transform(df2['financial']) \n",
    "df2['support'] = labelencoder.fit_transform(df2['support']) \n",
    "df2['attitude'] = labelencoder.fit_transform(df2['attitude']) \n",
    "df2['confess'] = labelencoder.fit_transform(df2['confess']) \n",
    "df2['law'] = labelencoder.fit_transform(df2['law'])\n",
    "df2['sequel'] = labelencoder.fit_transform(df2['sequel']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全資料\n",
    "X = df2.drop(['label','id','years'],axis=1)\n",
    "y = df2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 309-1\n",
    "law = df2.groupby('law')\n",
    "df_insult1 = law.get_group(0)\n",
    "# df_insult1 = df_insult1.sample(200)\n",
    "X1 = df_insult1.drop(['label','id','years','law'],axis=1)\n",
    "y1 = df_insult1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 309-2\n",
    "law = df2.groupby('law')\n",
    "df_insult2 = law.get_group(1)\n",
    "X2 = df_insult2.drop(['label','id','years','law'],axis=1)\n",
    "y2 = df_insult2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 310-1\n",
    "law = df2.groupby('law')\n",
    "df_insult3 = law.get_group(2)\n",
    "# df_insult3 = df_insult3.sample(200)\n",
    "X3 = df_insult3.drop(['label','id','years','law'],axis=1)\n",
    "y3 = df_insult3['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 310-2\n",
    "law = df2.groupby('law')\n",
    "df_insult4 = law.get_group(3)\n",
    "# df_insult4 = df_insult4.sample(200)\n",
    "X4 = df_insult4.drop(['label','id','years','law'],axis=1)\n",
    "y4 = df_insult4['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction (MDS、PCA、Isomap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X1\n",
    "y_test=y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds=MDS(n_components=2) \n",
    "mds.fit(X_test)\n",
    "X_mds=mds.fit_transform(X_test)\n",
    "plt.scatter(X_mds[:,0],X_mds[:,1],c=y_test,alpha=.5)\n",
    "plt.colorbar()\n",
    "plt.title('Using sklearn MDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "pca.fit(X_test)\n",
    "X_PCA=pca.fit_transform(X_test)\n",
    "plt.scatter(X_PCA[:,0],X_PCA[:,1],c=y_test,alpha=.5)\n",
    "plt.colorbar ()\n",
    "plt.title('Using sklearn PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "iso=Isomap(n_components=2)\n",
    "iso.fit(X_test)\n",
    "X_iso=iso.transform(X_test)\n",
    "plt.scatter(X_iso[:,0],X_iso[:,1],c=y_test,alpha=.5)\n",
    "plt.colorbar()\n",
    "plt.title('Using sklearn Isomap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "# estimator =  neighbors.KNeighborsClassifier(algorithm = 'brute', n_neighbors = 3, weights = 'distance', p = 1)\n",
    "estimator = RandomForestClassifier(max_depth=6, n_estimators=10)\n",
    "# estimator = linear_model.LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=1, step=1)\n",
    "selector = selector.fit(X_test, y_test)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)\n",
    "for i in selector.ranking_:\n",
    "    i = i-1\n",
    "    print(X1.columns[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
